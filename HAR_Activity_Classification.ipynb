{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c86464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# HUMAN ACTIVITY RECOGNITION - CMPE 287\n",
    "# Team: SANNS\n",
    "# Members: Salma Ibrahim, Sana Al Hamimidi, Akmal Shaikh, Nicholas Faylor, Noah Scheuerman\n",
    "# Date: 11/14/2025\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This project classifies 18 different human activities using smartphone \n",
    "sensor data (accelerometer and gyroscope) from the KU-HAR dataset.\n",
    "\n",
    "We use two machine learning models:\n",
    "1. Random Forest Classifier\n",
    "2. Support Vector Machine (SVM)\n",
    "\n",
    "Dataset: 20,750 samples from 90 participants\n",
    "Activities: Walking, Running, Sitting, Standing, Jumping, etc.\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================\n",
    "# SECTION 1: SETUP & IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning - Model Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning - Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Machine Learning - Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Machine Learning - Evaluation Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Utilities\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Set visualization defaults\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")\n",
    "print(f\"✓ Random state set to: {RANDOM_STATE}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(f\"✓ Pandas version: {pd.__version__}\")\n",
    "print(\"\\nReady to load data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89099f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 2: LOAD DATASET\n",
    "# ============================================================\n",
    "\n",
    "# Define activity labels (Class IDs 0-17)\n",
    "activity_names = {\n",
    "    0: 'Stand',\n",
    "    1: 'Sit',\n",
    "    2: 'Talk-sit',\n",
    "    3: 'Talk-stand',\n",
    "    4: 'Stand-sit',\n",
    "    5: 'Lay',\n",
    "    6: 'Lay-stand',\n",
    "    7: 'Pick',\n",
    "    8: 'Jump',\n",
    "    9: 'Push-up',\n",
    "    10: 'Sit-up',\n",
    "    11: 'Walk',\n",
    "    12: 'Walk-backward',\n",
    "    13: 'Walk-circle',\n",
    "    14: 'Run',\n",
    "    15: 'Stair-up',\n",
    "    16: 'Stair-down',\n",
    "    17: 'Table-tennis'\n",
    "}\n",
    "\n",
    "print(\"Loading KU-HAR Time Domain Subsamples dataset...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load the dataset (no header in CSV)\n",
    "# NOTE: Update the path to match where you saved the CSV file\n",
    "df = pd.read_csv('data/time_domain_subsamples.csv', header=None)\n",
    "\n",
    "print(f\"✓ Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset Shape: {df.shape}\")\n",
    "print(f\"  - Total samples: {df.shape[0]:,}\")\n",
    "print(f\"  - Total columns: {df.shape[1]:,}\")\n",
    "\n",
    "# Extract labels (column 1800 contains class IDs 0-17)\n",
    "labels = df.iloc[:, 1800]\n",
    "\n",
    "print(f\"\\n{'Activity Distribution:'}\")\n",
    "print(\"=\" * 60)\n",
    "class_distribution = labels.value_counts().sort_index()\n",
    "\n",
    "for class_id, count in class_distribution.items():\n",
    "    activity_name = activity_names[class_id]\n",
    "    percentage = (count / len(labels)) * 100\n",
    "    print(f\"  {class_id:2d}. {activity_name:15s}: {count:4d} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "print(f\"\\n{'Dataset Summary:'}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  - Sensor readings per sample: 1,800 (300 points × 6 axes)\")\n",
    "print(f\"  - Sampling rate: 100 Hz\")\n",
    "print(f\"  - Window duration: 3 seconds\")\n",
    "print(f\"  - Number of activities: 18\")\n",
    "print(f\"  - Total participants: 90\")\n",
    "\n",
    "# Verify data structure\n",
    "print(f\"\\n{'Data Structure Verification:'}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  - Columns 0-299:      Accelerometer X\")\n",
    "print(f\"  - Columns 300-599:    Accelerometer Y\")\n",
    "print(f\"  - Columns 600-899:    Accelerometer Z\")\n",
    "print(f\"  - Columns 900-1199:   Gyroscope X\")\n",
    "print(f\"  - Columns 1200-1499:  Gyroscope Y\")\n",
    "print(f\"  - Columns 1500-1799:  Gyroscope Z\")\n",
    "print(f\"  - Column 1800:        Class ID (0-17)\")\n",
    "print(f\"  - Column 1801:        Data length\")\n",
    "print(f\"  - Column 1802:        Serial number\")\n",
    "\n",
    "print(\"\\n✓ Ready for feature extraction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3151e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 3: FEATURE EXTRACTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Converting 1,800 raw sensor values per sample into 24 statistical features\")\n",
    "print()\n",
    "\n",
    "def extract_features(row):\n",
    "    \"\"\"\n",
    "    Extract statistical features from time-series sensor data.\n",
    "    \n",
    "    For each of the 6 sensor axes (Accel X/Y/Z, Gyro X/Y/Z), we extract:\n",
    "    - Mean: Average value over 3 seconds\n",
    "    - Std: Standard deviation (variability)\n",
    "    - Max: Maximum value\n",
    "    - Min: Minimum value\n",
    "    \n",
    "    Total: 6 axes × 4 statistics = 24 features\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Accelerometer X (columns 0-299)\n",
    "    accel_x = row[0:300].values\n",
    "    features['accel_x_mean'] = np.mean(accel_x)\n",
    "    features['accel_x_std'] = np.std(accel_x)\n",
    "    features['accel_x_max'] = np.max(accel_x)\n",
    "    features['accel_x_min'] = np.min(accel_x)\n",
    "    \n",
    "    # Accelerometer Y (columns 300-599)\n",
    "    accel_y = row[300:600].values\n",
    "    features['accel_y_mean'] = np.mean(accel_y)\n",
    "    features['accel_y_std'] = np.std(accel_y)\n",
    "    features['accel_y_max'] = np.max(accel_y)\n",
    "    features['accel_y_min'] = np.min(accel_y)\n",
    "    \n",
    "    # Accelerometer Z (columns 600-899)\n",
    "    accel_z = row[600:900].values\n",
    "    features['accel_z_mean'] = np.mean(accel_z)\n",
    "    features['accel_z_std'] = np.std(accel_z)\n",
    "    features['accel_z_max'] = np.max(accel_z)\n",
    "    features['accel_z_min'] = np.min(accel_z)\n",
    "    \n",
    "    # Gyroscope X (columns 900-1199)\n",
    "    gyro_x = row[900:1200].values\n",
    "    features['gyro_x_mean'] = np.mean(gyro_x)\n",
    "    features['gyro_x_std'] = np.std(gyro_x)\n",
    "    features['gyro_x_max'] = np.max(gyro_x)\n",
    "    features['gyro_x_min'] = np.min(gyro_x)\n",
    "    \n",
    "    # Gyroscope Y (columns 1200-1499)\n",
    "    gyro_y = row[1200:1500].values\n",
    "    features['gyro_y_mean'] = np.mean(gyro_y)\n",
    "    features['gyro_y_std'] = np.std(gyro_y)\n",
    "    features['gyro_y_max'] = np.max(gyro_y)\n",
    "    features['gyro_y_min'] = np.min(gyro_y)\n",
    "    \n",
    "    # Gyroscope Z (columns 1500-1799)\n",
    "    gyro_z = row[1500:1800].values\n",
    "    features['gyro_z_mean'] = np.mean(gyro_z)\n",
    "    features['gyro_z_std'] = np.std(gyro_z)\n",
    "    features['gyro_z_max'] = np.max(gyro_z)\n",
    "    features['gyro_z_min'] = np.min(gyro_z)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Extract features for all samples\n",
    "print(\"Extracting features from all 20,750 samples...\")\n",
    "print(\"This may take a minute or two...\\n\")\n",
    "\n",
    "feature_list = []\n",
    "total_samples = len(df)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    feature_list.append(extract_features(row))\n",
    "    \n",
    "    # Progress update every 5,000 samples\n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        progress = ((idx + 1) / total_samples) * 100\n",
    "        print(f\"  Progress: {idx + 1:,}/{total_samples:,} samples ({progress:.1f}%)\")\n",
    "\n",
    "print(f\"  Progress: {total_samples:,}/{total_samples:,} samples (100.0%)\")\n",
    "\n",
    "# Create feature DataFrame\n",
    "features_df = pd.DataFrame(feature_list)\n",
    "\n",
    "print(f\"\\n✓ Feature extraction complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Feature Matrix Shape: {features_df.shape}\")\n",
    "print(f\"  - Samples: {features_df.shape[0]:,}\")\n",
    "print(f\"  - Features per sample: {features_df.shape[1]}\")\n",
    "\n",
    "print(f\"\\nExtracted Features:\")\n",
    "print(\"-\" * 60)\n",
    "for i, col in enumerate(features_df.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(f\"\\nFeature Statistics (first 5 features):\")\n",
    "print(\"-\" * 60)\n",
    "print(features_df.iloc[:, :5].describe())\n",
    "\n",
    "print(\"\\n✓ Ready for train-test split!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180a2652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 4: TRAIN-TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Split: 80% training, 20% testing\n",
    "# Stratify ensures each activity is proportionally represented in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_df,           # Feature matrix (24 features)\n",
    "    labels,                # Class labels (0-17)\n",
    "    test_size=0.2,         # 20% for testing\n",
    "    stratify=labels,       # Maintain class distribution\n",
    "    random_state=RANDOM_STATE  # Reproducibility\n",
    ")\n",
    "\n",
    "print(f\"✓ Data split complete!\")\n",
    "print()\n",
    "\n",
    "# Display split information\n",
    "print(f\"{'Dataset Split Summary:'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"  Training samples:   {len(X_train):,} ({len(X_train)/len(features_df)*100:.1f}%)\")\n",
    "print(f\"  Testing samples:    {len(X_test):,} ({len(X_test)/len(features_df)*100:.1f}%)\")\n",
    "print(f\"  Total samples:      {len(features_df):,}\")\n",
    "print()\n",
    "print(f\"  Features per sample: {X_train.shape[1]}\")\n",
    "\n",
    "# Verify stratification worked - show class distribution in train/test\n",
    "print(f\"\\n{'Class Distribution Verification:'}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Activity':<20} {'Train Count':<15} {'Test Count':<15} {'Train %':<10} {'Test %'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "train_dist = y_train.value_counts().sort_index()\n",
    "test_dist = y_test.value_counts().sort_index()\n",
    "\n",
    "for class_id in range(18):\n",
    "    activity = activity_names[class_id]\n",
    "    train_count = train_dist.get(class_id, 0)\n",
    "    test_count = test_dist.get(class_id, 0)\n",
    "    train_pct = (train_count / len(y_train)) * 100\n",
    "    test_pct = (test_count / len(y_test)) * 100\n",
    "    \n",
    "    print(f\"{activity:<20} {train_count:<15} {test_count:<15} {train_pct:<10.2f} {test_pct:.2f}\")\n",
    "\n",
    "print()\n",
    "print(\"✓ Stratification successful - distributions are proportional!\")\n",
    "print(\"\\n✓ Ready for feature scaling!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19960b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 5: FEATURE SCALING (FIXED WITH ROBUST SCALER)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "print(\"Scaling features using RobustScaler...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Why RobustScaler? It handles outliers better than StandardScaler.\")\n",
    "print(\"Uses median and IQR instead of mean and std.\\n\")\n",
    "\n",
    "# Initialize RobustScaler (robust to outliers)\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit on training data only, then transform both sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"✓ Feature scaling complete!\")\n",
    "print()\n",
    "\n",
    "# Show scaling effect\n",
    "print(f\"{'Scaling Effect (example: accel_x_mean):'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Before scaling:\")\n",
    "print(f\"  Training median: {X_train.iloc[:, 0].median():.4f}\")\n",
    "print(f\"  Training IQR:    {X_train.iloc[:, 0].quantile(0.75) - X_train.iloc[:, 0].quantile(0.25):.4f}\")\n",
    "print()\n",
    "print(f\"After scaling:\")\n",
    "print(f\"  Training median: {X_train_scaled[:, 0].mean():.4f}\")\n",
    "print(f\"  Data range: [{X_train_scaled.min():.4f}, {X_train_scaled.max():.4f}]\")\n",
    "print()\n",
    "print(\"Features now scaled robustly (handles outliers)\")\n",
    "\n",
    "print(\"\\n✓ Ready to train models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e338aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 6: TRAIN RANDOM FOREST MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"Training Random Forest Classifier...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,        # 100 decision trees\n",
    "    max_depth=None,          # No limit on tree depth\n",
    "    min_samples_split=2,     # Minimum samples to split a node\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1                # Use all CPU cores\n",
    ")\n",
    "\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"  - Number of trees: 100\")\n",
    "print(f\"  - Max depth: Unlimited\")\n",
    "print(f\"  - Random state: {RANDOM_STATE}\")\n",
    "print()\n",
    "\n",
    "# Train the model\n",
    "print(\"Training in progress...\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"✓ Training complete! Time: {training_time:.2f} seconds\")\n",
    "print()\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions on test set...\")\n",
    "y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_scaled)\n",
    "\n",
    "print(\"✓ Predictions complete!\")\n",
    "print()\n",
    "\n",
    "# Quick accuracy preview\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"=\" * 60)\n",
    "print(f\"RANDOM FOREST - QUICK PREVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test Set Accuracy: {rf_accuracy*100:.2f}%\")\n",
    "print()\n",
    "print(\"(Detailed evaluation in next sections)\")\n",
    "\n",
    "print(\"\\n✓ Random Forest model trained successfully!\")\n",
    "print(\"✓ Ready to train SVM model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd491cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 7: TRAIN SVM MODEL (WITH ROBUST SCALING)\n",
    "# ============================================================\n",
    "\n",
    "print(\"Training SVM Classifier (with RobustScaler data)...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use linear kernel - simpler and more stable\n",
    "svm_model = SVC(\n",
    "    kernel='linear',\n",
    "    C=1.0,\n",
    "    random_state=RANDOM_STATE,\n",
    "    max_iter=5000\n",
    ")\n",
    "\n",
    "print(f\"Model configuration:\")\n",
    "print(f\"  - Kernel: Linear\")\n",
    "print(f\"  - C: 1.0\")\n",
    "print(f\"  - Data: RobustScaler (handles outliers)\")\n",
    "print()\n",
    "\n",
    "# Train\n",
    "print(\"Training in progress...\")\n",
    "start_time = time.time()\n",
    "\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"✓ Training complete! Time: {training_time:.2f} seconds\")\n",
    "print()\n",
    "\n",
    "# Predict\n",
    "print(\"Making predictions on test set...\")\n",
    "y_pred_svm = svm_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"✓ Predictions complete!\")\n",
    "print()\n",
    "\n",
    "# Accuracy\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"=\" * 60)\n",
    "print(f\"SVM - RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Test Set Accuracy: {svm_accuracy*100:.2f}%\")\n",
    "print(f\"Classes predicted: {len(np.unique(y_pred_svm))}/18\")\n",
    "print()\n",
    "\n",
    "# Compare\n",
    "print(\"=\" * 60)\n",
    "print(f\"MODEL COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy*100:.2f}%\")\n",
    "print(f\"SVM Accuracy:           {svm_accuracy*100:.2f}%\")\n",
    "print(f\"Difference:             {abs(rf_accuracy - svm_accuracy)*100:.2f}%\")\n",
    "\n",
    "if rf_accuracy > svm_accuracy:\n",
    "    print(f\"\\n→ Random Forest performs better by {(rf_accuracy - svm_accuracy)*100:.2f}%\")\n",
    "elif svm_accuracy > rf_accuracy:\n",
    "    print(f\"\\n→ SVM performs better by {(svm_accuracy - rf_accuracy)*100:.2f}%\")\n",
    "\n",
    "print(\"\\n✓ Both models trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eed9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 8: DETAILED EVALUATION METRICS\n",
    "# ============================================================\n",
    "\n",
    "print(\"Generating detailed evaluation metrics for both models...\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# RANDOM FOREST - DETAILED METRICS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RANDOM FOREST - DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "rf_report = classification_report(\n",
    "    y_test, \n",
    "    y_pred_rf,\n",
    "    target_names=[activity_names[i] for i in range(18)],\n",
    "    digits=4,\n",
    "    output_dict=False\n",
    ")\n",
    "print(rf_report)\n",
    "\n",
    "# Get per-class metrics as dictionary for later analysis\n",
    "rf_report_dict = classification_report(\n",
    "    y_test, \n",
    "    y_pred_rf,\n",
    "    target_names=[activity_names[i] for i in range(18)],\n",
    "    digits=4,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RANDOM FOREST - PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall metrics\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  Accuracy:          {rf_accuracy*100:.2f}%\")\n",
    "print(f\"  Macro Avg F1:      {rf_report_dict['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"  Weighted Avg F1:   {rf_report_dict['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Best performing activities\n",
    "print(f\"\\nTop 5 Best Performing Activities (by F1-score):\")\n",
    "activity_scores_rf = [(activity_names[i], rf_report_dict[activity_names[i]]['f1-score']) \n",
    "                      for i in range(18)]\n",
    "activity_scores_rf.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (activity, score) in enumerate(activity_scores_rf[:5], 1):\n",
    "    print(f\"  {i}. {activity:<20} F1: {score:.4f}\")\n",
    "\n",
    "# Worst performing activities\n",
    "print(f\"\\nBottom 5 Challenging Activities (by F1-score):\")\n",
    "for i, (activity, score) in enumerate(activity_scores_rf[-5:], 1):\n",
    "    print(f\"  {i}. {activity:<20} F1: {score:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "# ============================================================\n",
    "# SVM - DETAILED METRICS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SVM - DETAILED CLASSIFICATION REPORT\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "svm_report = classification_report(\n",
    "    y_test, \n",
    "    y_pred_svm,\n",
    "    target_names=[activity_names[i] for i in range(18)],\n",
    "    digits=4,\n",
    "    output_dict=False,\n",
    "    zero_division=0  # Handle missing classes gracefully\n",
    ")\n",
    "print(svm_report)\n",
    "\n",
    "# Get per-class metrics as dictionary\n",
    "svm_report_dict = classification_report(\n",
    "    y_test, \n",
    "    y_pred_svm,\n",
    "    target_names=[activity_names[i] for i in range(18)],\n",
    "    digits=4,\n",
    "    output_dict=True,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SVM - PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall metrics\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"  Accuracy:          {svm_accuracy*100:.2f}%\")\n",
    "print(f\"  Macro Avg F1:      {svm_report_dict['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"  Weighted Avg F1:   {svm_report_dict['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Best performing activities\n",
    "print(f\"\\nTop 5 Best Performing Activities (by F1-score):\")\n",
    "activity_scores_svm = [(activity_names[i], svm_report_dict[activity_names[i]]['f1-score']) \n",
    "                       for i in range(18)]\n",
    "activity_scores_svm.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for i, (activity, score) in enumerate(activity_scores_svm[:5], 1):\n",
    "    print(f\"  {i}. {activity:<20} F1: {score:.4f}\")\n",
    "\n",
    "# Worst performing activities\n",
    "print(f\"\\nBottom 5 Challenging Activities (by F1-score):\")\n",
    "for i, (activity, score) in enumerate(activity_scores_svm[-5:], 1):\n",
    "    print(f\"  {i}. {activity:<20} F1: {score:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "\n",
    "# ============================================================\n",
    "# COMPARATIVE ANALYSIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPARATIVE ANALYSIS - RF vs SVM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{'Activity':<20} {'RF F1':<12} {'SVM F1':<12} {'Difference':<12} {'Winner'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i in range(18):\n",
    "    activity = activity_names[i]\n",
    "    rf_f1 = rf_report_dict[activity]['f1-score']\n",
    "    svm_f1 = svm_report_dict[activity]['f1-score']\n",
    "    diff = rf_f1 - svm_f1\n",
    "    winner = \"RF\" if rf_f1 > svm_f1 else (\"SVM\" if svm_f1 > rf_f1 else \"Tie\")\n",
    "    \n",
    "    print(f\"{activity:<20} {rf_f1:<12.4f} {svm_f1:<12.4f} {diff:>+11.4f} {winner}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Count how many activities each model wins\n",
    "rf_wins = sum(1 for i in range(18) if rf_report_dict[activity_names[i]]['f1-score'] > \n",
    "              svm_report_dict[activity_names[i]]['f1-score'])\n",
    "svm_wins = sum(1 for i in range(18) if svm_report_dict[activity_names[i]]['f1-score'] > \n",
    "               rf_report_dict[activity_names[i]]['f1-score'])\n",
    "ties = 18 - rf_wins - svm_wins\n",
    "\n",
    "print(f\"\\nPer-Activity Performance:\")\n",
    "print(f\"  Random Forest wins: {rf_wins}/18 activities\")\n",
    "print(f\"  SVM wins:           {svm_wins}/18 activities\")\n",
    "print(f\"  Ties:               {ties}/18 activities\")\n",
    "\n",
    "# Average performance gap\n",
    "avg_gap = np.mean([rf_report_dict[activity_names[i]]['f1-score'] - \n",
    "                   svm_report_dict[activity_names[i]]['f1-score'] \n",
    "                   for i in range(18)])\n",
    "print(f\"\\nAverage F1-score gap: {avg_gap:+.4f} (positive = RF better)\")\n",
    "\n",
    "# Find activities where SVM did surprisingly well\n",
    "print(f\"\\nActivities where SVM performed competitively (within 5% of RF):\")\n",
    "competitive = []\n",
    "for i in range(18):\n",
    "    activity = activity_names[i]\n",
    "    rf_f1 = rf_report_dict[activity]['f1-score']\n",
    "    svm_f1 = svm_report_dict[activity]['f1-score']\n",
    "    if abs(rf_f1 - svm_f1) <= 0.05:\n",
    "        competitive.append((activity, rf_f1, svm_f1))\n",
    "\n",
    "if competitive:\n",
    "    for activity, rf_f1, svm_f1 in competitive:\n",
    "        print(f\"  - {activity:<20} RF: {rf_f1:.4f}, SVM: {svm_f1:.4f}\")\n",
    "else:\n",
    "    print(\"  None - Random Forest dominates across all activities\")\n",
    "\n",
    "print(\"\\n✓ Detailed evaluation complete!\")\n",
    "print(\"✓ Ready for confusion matrix visualization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 9: CONFUSION MATRIX VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"Generating confusion matrices for both models...\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Calculate confusion matrices\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "cm_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "\n",
    "# Activity names for labels\n",
    "activity_labels = [activity_names[i] for i in range(18)]\n",
    "\n",
    "# ============================================================\n",
    "# PLOT SIDE-BY-SIDE CONFUSION MATRICES\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(24, 10))\n",
    "\n",
    "# Random Forest Confusion Matrix\n",
    "sns.heatmap(\n",
    "    cm_rf,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=activity_labels,\n",
    "    yticklabels=activity_labels,\n",
    "    ax=axes[0],\n",
    "    cbar_kws={'label': 'Number of Samples'}\n",
    ")\n",
    "axes[0].set_xlabel('Predicted Activity', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Actual Activity', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Random Forest Confusion Matrix\\nAccuracy: {rf_accuracy*100:.2f}%', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "sns.heatmap(\n",
    "    cm_svm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Greens',\n",
    "    xticklabels=activity_labels,\n",
    "    yticklabels=activity_labels,\n",
    "    ax=axes[1],\n",
    "    cbar_kws={'label': 'Number of Samples'}\n",
    ")\n",
    "axes[1].set_xlabel('Predicted Activity', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Actual Activity', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'SVM Confusion Matrix\\nAccuracy: {svm_accuracy*100:.2f}%', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].tick_params(axis='y', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrices_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrices plotted!\")\n",
    "print(\"✓ Saved as: confusion_matrices_comparison.png\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# ANALYZE CONFUSION PATTERNS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONFUSION PATTERN ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Random Forest - Most Common Misclassifications\n",
    "print(\"RANDOM FOREST - Top 10 Misclassification Pairs:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rf_errors = []\n",
    "for i in range(18):\n",
    "    for j in range(18):\n",
    "        if i != j and cm_rf[i][j] > 0:\n",
    "            rf_errors.append((activity_names[i], activity_names[j], cm_rf[i][j]))\n",
    "\n",
    "rf_errors.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "for idx, (true_class, pred_class, count) in enumerate(rf_errors[:10], 1):\n",
    "    percentage = (count / cm_rf[list(activity_names.values()).index(true_class), :].sum()) * 100\n",
    "    print(f\"  {idx:2d}. {true_class:<15} → {pred_class:<15} : {count:3d} errors ({percentage:5.2f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# SVM - Most Common Misclassifications\n",
    "print(\"SVM - Top 10 Misclassification Pairs:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "svm_errors = []\n",
    "for i in range(18):\n",
    "    for j in range(18):\n",
    "        if i != j and cm_svm[i][j] > 0:\n",
    "            svm_errors.append((activity_names[i], activity_names[j], cm_svm[i][j]))\n",
    "\n",
    "svm_errors.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "for idx, (true_class, pred_class, count) in enumerate(svm_errors[:10], 1):\n",
    "    percentage = (count / cm_svm[list(activity_names.values()).index(true_class), :].sum()) * 100\n",
    "    print(f\"  {idx:2d}. {true_class:<15} → {pred_class:<15} : {count:3d} errors ({percentage:5.2f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# PER-CLASS ACCURACY FROM CONFUSION MATRIX\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PER-CLASS ACCURACY (from Confusion Matrix)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(f\"{'Activity':<20} {'RF Accuracy':<15} {'SVM Accuracy':<15} {'Difference'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i in range(18):\n",
    "    activity = activity_names[i]\n",
    "    \n",
    "    # Calculate per-class accuracy (diagonal / row sum)\n",
    "    rf_class_acc = cm_rf[i][i] / cm_rf[i, :].sum() if cm_rf[i, :].sum() > 0 else 0\n",
    "    svm_class_acc = cm_svm[i][i] / cm_svm[i, :].sum() if cm_svm[i, :].sum() > 0 else 0\n",
    "    diff = rf_class_acc - svm_class_acc\n",
    "    \n",
    "    print(f\"{activity:<20} {rf_class_acc*100:>6.2f}%        {svm_class_acc*100:>6.2f}%        {diff*100:>+6.2f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# KEY INSIGHTS FROM CONFUSION MATRICES\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Find activities that are commonly confused with each other (both models)\n",
    "print(\"Activities Commonly Confused by BOTH Models:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "common_confusions = []\n",
    "for i in range(18):\n",
    "    for j in range(18):\n",
    "        if i != j:\n",
    "            # If both models confuse these activities significantly\n",
    "            rf_conf = cm_rf[i][j]\n",
    "            svm_conf = cm_svm[i][j]\n",
    "            if rf_conf >= 5 and svm_conf >= 5:  # At least 5 errors in both\n",
    "                common_confusions.append((activity_names[i], activity_names[j], rf_conf, svm_conf))\n",
    "\n",
    "if common_confusions:\n",
    "    for true_act, pred_act, rf_err, svm_err in common_confusions:\n",
    "        print(f\"  {true_act:<15} → {pred_act:<15} : RF={rf_err:3d} errors, SVM={svm_err:3d} errors\")\n",
    "else:\n",
    "    print(\"  No common confusion patterns found\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Activities with perfect classification (RF)\n",
    "perfect_rf = [activity_names[i] for i in range(18) if cm_rf[i][i] == cm_rf[i, :].sum()]\n",
    "if perfect_rf:\n",
    "    print(f\"Activities with PERFECT classification by Random Forest:\")\n",
    "    for activity in perfect_rf:\n",
    "        print(f\"  ✓ {activity}\")\n",
    "    print()\n",
    "\n",
    "# Activities with perfect classification (SVM)\n",
    "perfect_svm = [activity_names[i] for i in range(18) if cm_svm[i][i] == cm_svm[i, :].sum()]\n",
    "if perfect_svm:\n",
    "    print(f\"Activities with PERFECT classification by SVM:\")\n",
    "    for activity in perfect_svm:\n",
    "        print(f\"  ✓ {activity}\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"No activities perfectly classified by SVM\")\n",
    "    print()\n",
    "\n",
    "# Most problematic activity for each model\n",
    "print(\"Most Challenging Activity for Each Model:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rf_worst_idx = np.argmin([cm_rf[i][i] / cm_rf[i, :].sum() for i in range(18)])\n",
    "svm_worst_idx = np.argmin([cm_svm[i][i] / cm_svm[i, :].sum() if cm_svm[i, :].sum() > 0 else 1 \n",
    "                           for i in range(18)])\n",
    "\n",
    "rf_worst_acc = cm_rf[rf_worst_idx][rf_worst_idx] / cm_rf[rf_worst_idx, :].sum()\n",
    "svm_worst_acc = cm_svm[svm_worst_idx][svm_worst_idx] / cm_svm[svm_worst_idx, :].sum() if cm_svm[svm_worst_idx, :].sum() > 0 else 0\n",
    "\n",
    "print(f\"  Random Forest: {activity_names[rf_worst_idx]} ({rf_worst_acc*100:.2f}% accuracy)\")\n",
    "print(f\"  SVM:           {activity_names[svm_worst_idx]} ({svm_worst_acc*100:.2f}% accuracy)\")\n",
    "\n",
    "print()\n",
    "print(\"✓ Confusion matrix analysis complete!\")\n",
    "print(\"✓ Ready for feature importance analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a230e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 10: FEATURE IMPORTANCE ANALYSIS (RANDOM FOREST)\n",
    "# ============================================================\n",
    "\n",
    "print(\"Analyzing feature importance from Random Forest...\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Get feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features_df.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE RANKING\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(f\"{'Rank':<6} {'Feature':<25} {'Importance':<15} {'Cumulative %'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "cumulative = 0\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    cumulative += row['importance']\n",
    "    print(f\"{feature_importance.index.get_loc(idx)+1:<6} {row['feature']:<25} {row['importance']:<15.6f} {cumulative*100:>6.2f}%\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZE TOP FEATURES\n",
    "# ============================================================\n",
    "\n",
    "print(\"Plotting feature importance...\")\n",
    "print()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Top 15 Features (Bar Chart)\n",
    "top_15 = feature_importance.head(15)\n",
    "\n",
    "axes[0].barh(range(len(top_15)), top_15['importance'], color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_15)))\n",
    "axes[0].set_yticklabels(top_15['feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "axes[0].set_title('Top 15 Most Important Features', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add importance values on bars\n",
    "for i, (idx, row) in enumerate(top_15.iterrows()):\n",
    "    axes[0].text(row['importance'], i, f\" {row['importance']:.4f}\", \n",
    "                va='center', fontsize=9)\n",
    "\n",
    "# Plot 2: Feature Importance by Category\n",
    "axes[1].bar(range(len(feature_importance)), feature_importance['importance'], \n",
    "           color='coral', alpha=0.7)\n",
    "axes[1].set_xlabel('Feature Rank', fontsize=11, fontweight='bold')\n",
    "axes[1].set_ylabel('Importance Score', fontsize=11, fontweight='bold')\n",
    "axes[1].set_title('Feature Importance Distribution (All 24 Features)', \n",
    "                 fontsize=13, fontweight='bold')\n",
    "axes[1].set_xticks(range(0, 24, 2))\n",
    "axes[1].set_xticklabels(range(1, 25, 2))\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Feature importance visualization saved!\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# ANALYZE BY SENSOR AND STATISTIC TYPE\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE BY SENSOR TYPE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Group by sensor (accel vs gyro)\n",
    "accel_importance = feature_importance[feature_importance['feature'].str.contains('accel')]['importance'].sum()\n",
    "gyro_importance = feature_importance[feature_importance['feature'].str.contains('gyro')]['importance'].sum()\n",
    "\n",
    "print(f\"Accelerometer features total importance: {accel_importance:.6f} ({accel_importance*100:.2f}%)\")\n",
    "print(f\"Gyroscope features total importance:     {gyro_importance:.6f} ({gyro_importance*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "if accel_importance > gyro_importance:\n",
    "    print(f\"→ Accelerometer is {accel_importance/gyro_importance:.2f}x more important than Gyroscope\")\n",
    "else:\n",
    "    print(f\"→ Gyroscope is {gyro_importance/accel_importance:.2f}x more important than Accelerometer\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# ANALYZE BY STATISTIC TYPE\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE BY STATISTIC TYPE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "mean_importance = feature_importance[feature_importance['feature'].str.contains('mean')]['importance'].sum()\n",
    "std_importance = feature_importance[feature_importance['feature'].str.contains('std')]['importance'].sum()\n",
    "max_importance = feature_importance[feature_importance['feature'].str.contains('max')]['importance'].sum()\n",
    "min_importance = feature_importance[feature_importance['feature'].str.contains('min')]['importance'].sum()\n",
    "\n",
    "print(f\"Mean features total importance: {mean_importance:.6f} ({mean_importance*100:.2f}%)\")\n",
    "print(f\"Std features total importance:  {std_importance:.6f} ({std_importance*100:.2f}%)\")\n",
    "print(f\"Max features total importance:  {max_importance:.6f} ({max_importance*100:.2f}%)\")\n",
    "print(f\"Min features total importance:  {min_importance:.6f} ({min_importance*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Find most important statistic\n",
    "stats = {\n",
    "    'Mean': mean_importance,\n",
    "    'Std': std_importance,\n",
    "    'Max': max_importance,\n",
    "    'Min': min_importance\n",
    "}\n",
    "most_important_stat = max(stats, key=stats.get)\n",
    "print(f\"→ Most important statistic type: {most_important_stat} ({stats[most_important_stat]*100:.2f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# ANALYZE BY AXIS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE BY SENSOR AXIS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "x_importance = feature_importance[feature_importance['feature'].str.contains('_x_')]['importance'].sum()\n",
    "y_importance = feature_importance[feature_importance['feature'].str.contains('_y_')]['importance'].sum()\n",
    "z_importance = feature_importance[feature_importance['feature'].str.contains('_z_')]['importance'].sum()\n",
    "\n",
    "print(f\"X-axis features total importance: {x_importance:.6f} ({x_importance*100:.2f}%)\")\n",
    "print(f\"Y-axis features total importance: {y_importance:.6f} ({y_importance*100:.2f}%)\")\n",
    "print(f\"Z-axis features total importance: {z_importance:.6f} ({z_importance*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "axes_dict = {'X': x_importance, 'Y': y_importance, 'Z': z_importance}\n",
    "most_important_axis = max(axes_dict, key=axes_dict.get)\n",
    "print(f\"→ Most important axis: {most_important_axis}-axis ({axes_dict[most_important_axis]*100:.2f}%)\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# KEY INSIGHTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "top_feature = feature_importance.iloc[0]\n",
    "print(f\"Most Important Feature: {top_feature['feature']}\")\n",
    "print(f\"  Importance: {top_feature['importance']:.6f} ({top_feature['importance']*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "# Features needed for 80% importance\n",
    "cumulative_importance = 0\n",
    "features_for_80 = 0\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    cumulative_importance += row['importance']\n",
    "    features_for_80 += 1\n",
    "    if cumulative_importance >= 0.80:\n",
    "        break\n",
    "\n",
    "print(f\"Number of features needed to reach 80% cumulative importance: {features_for_80}/24\")\n",
    "print(f\"  (This means {24 - features_for_80} features contribute only 20% to predictions)\")\n",
    "print()\n",
    "\n",
    "# Find least important features\n",
    "bottom_5 = feature_importance.tail(5)\n",
    "print(\"5 Least Important Features:\")\n",
    "for idx, row in bottom_5.iterrows():\n",
    "    print(f\"  - {row['feature']:<25} : {row['importance']:.6f}\")\n",
    "\n",
    "print()\n",
    "print(\"✓ Feature importance analysis complete!\")\n",
    "print(\"✓ Ready for final visualizations and summary!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478836cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 11: FINAL MODEL COMPARISON VISUALIZATIONS\n",
    "# ============================================================\n",
    "\n",
    "print(\"Creating final comparison visualizations...\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# VISUALIZATION 1: Overall Accuracy Comparison\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Overall Accuracy Bar Chart\n",
    "models = ['Random Forest', 'SVM']\n",
    "accuracies = [rf_accuracy * 100, svm_accuracy * 100]\n",
    "colors = ['steelblue', 'coral']\n",
    "\n",
    "bars = axes[0, 0].bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "axes[0, 0].set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Overall Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylim(0, 100)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                    f'{acc:.2f}%',\n",
    "                    ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add baseline reference line\n",
    "axes[0, 0].axhline(y=100/18, color='red', linestyle='--', linewidth=2, \n",
    "                   label=f'Random Guess ({100/18:.1f}%)')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# ============================================================\n",
    "# Plot 2: Per-Class Accuracy Comparison\n",
    "# ============================================================\n",
    "\n",
    "# Calculate per-class accuracies from confusion matrices\n",
    "rf_class_acc = [cm_rf[i][i] / cm_rf[i, :].sum() * 100 for i in range(18)]\n",
    "svm_class_acc = [cm_svm[i][i] / cm_svm[i, :].sum() * 100 if cm_svm[i, :].sum() > 0 else 0 \n",
    "                 for i in range(18)]\n",
    "\n",
    "x = np.arange(18)\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[0, 1].bar(x - width/2, rf_class_acc, width, label='Random Forest', \n",
    "                       color='steelblue', alpha=0.8)\n",
    "bars2 = axes[0, 1].bar(x + width/2, svm_class_acc, width, label='SVM', \n",
    "                       color='coral', alpha=0.8)\n",
    "\n",
    "axes[0, 1].set_xlabel('Activity', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Accuracy (%)', fontsize=11, fontweight='bold')\n",
    "axes[0, 1].set_title('Per-Activity Accuracy: RF vs SVM', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(range(18), fontsize=9)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "axes[0, 1].set_ylim(0, 105)\n",
    "\n",
    "# ============================================================\n",
    "# Plot 3: Performance Metrics Comparison (Precision, Recall, F1)\n",
    "# ============================================================\n",
    "\n",
    "metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "rf_metrics = [\n",
    "    rf_report_dict['weighted avg']['precision'] * 100,\n",
    "    rf_report_dict['weighted avg']['recall'] * 100,\n",
    "    rf_report_dict['weighted avg']['f1-score'] * 100\n",
    "]\n",
    "svm_metrics = [\n",
    "    svm_report_dict['weighted avg']['precision'] * 100,\n",
    "    svm_report_dict['weighted avg']['recall'] * 100,\n",
    "    svm_report_dict['weighted avg']['f1-score'] * 100\n",
    "]\n",
    "\n",
    "x_metrics = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[1, 0].bar(x_metrics - width/2, rf_metrics, width, \n",
    "                       label='Random Forest', color='steelblue', alpha=0.8)\n",
    "bars2 = axes[1, 0].bar(x_metrics + width/2, svm_metrics, width, \n",
    "                       label='SVM', color='coral', alpha=0.8)\n",
    "\n",
    "axes[1, 0].set_ylabel('Score (%)', fontsize=11, fontweight='bold')\n",
    "axes[1, 0].set_title('Performance Metrics Comparison (Weighted Avg)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xticks(x_metrics)\n",
    "axes[1, 0].set_xticklabels(metrics)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_ylim(0, 100)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                       f'{height:.1f}%',\n",
    "                       ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# ============================================================\n",
    "# Plot 4: Training Time and Model Characteristics\n",
    "# ============================================================\n",
    "\n",
    "# Summary statistics table\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Overall Accuracy',\n",
    "        'Weighted F1-Score',\n",
    "        'Macro F1-Score',\n",
    "        'Activities Won',\n",
    "        'Perfect Classifications'\n",
    "    ],\n",
    "    'Random Forest': [\n",
    "        f'{rf_accuracy*100:.2f}%',\n",
    "        f'{rf_report_dict[\"weighted avg\"][\"f1-score\"]:.4f}',\n",
    "        f'{rf_report_dict[\"macro avg\"][\"f1-score\"]:.4f}',\n",
    "        '17/18',\n",
    "        '0'  # Update if any were perfect\n",
    "    ],\n",
    "    'SVM': [\n",
    "        f'{svm_accuracy*100:.2f}%',\n",
    "        f'{svm_report_dict[\"weighted avg\"][\"f1-score\"]:.4f}',\n",
    "        f'{svm_report_dict[\"macro avg\"][\"f1-score\"]:.4f}',\n",
    "        '1/18',\n",
    "        '0'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create table\n",
    "axes[1, 1].axis('tight')\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "table = axes[1, 1].table(cellText=[[summary_data['Metric'][i], \n",
    "                                    summary_data['Random Forest'][i],\n",
    "                                    summary_data['SVM'][i]] \n",
    "                                   for i in range(len(summary_data['Metric']))],\n",
    "                        colLabels=['Metric', 'Random Forest', 'SVM'],\n",
    "                        cellLoc='center',\n",
    "                        loc='center',\n",
    "                        colWidths=[0.4, 0.3, 0.3])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# Style header row\n",
    "for i in range(3):\n",
    "    table[(0, i)].set_facecolor('#4472C4')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Alternate row colors\n",
    "for i in range(1, len(summary_data['Metric']) + 1):\n",
    "    if i % 2 == 0:\n",
    "        for j in range(3):\n",
    "            table[(i, j)].set_facecolor('#E7E6E6')\n",
    "\n",
    "axes[1, 1].set_title('Model Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Final comparison visualizations saved!\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY STATISTICS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINAL PROJECT SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"  Total Samples:               20,750\")\n",
    "print(f\"  Number of Activities:        18\")\n",
    "print(f\"  Features per Sample:         24 (extracted from 1,800 sensor readings)\")\n",
    "print(f\"  Training Samples:            16,600 (80%)\")\n",
    "print(f\"  Testing Samples:             4,150 (20%)\")\n",
    "print()\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"  Random Forest Accuracy:      {rf_accuracy*100:.2f}%\")\n",
    "print(f\"  SVM Accuracy:                {svm_accuracy*100:.2f}%\")\n",
    "print(f\"  Performance Gap:             {(rf_accuracy - svm_accuracy)*100:.2f}%\")\n",
    "print()\n",
    "\n",
    "print(\"Random Forest Details:\")\n",
    "print(f\"  Best Activity:               {activity_scores_rf[0][0]} (F1: {activity_scores_rf[0][1]:.4f})\")\n",
    "print(f\"  Worst Activity:              {activity_scores_rf[-1][0]} (F1: {activity_scores_rf[-1][1]:.4f})\")\n",
    "print(f\"  Activities Won (vs SVM):     17/18\")\n",
    "print(f\"  Weighted F1-Score:           {rf_report_dict['weighted avg']['f1-score']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"SVM Details:\")\n",
    "print(f\"  Best Activity:               {activity_scores_svm[0][0]} (F1: {activity_scores_svm[0][1]:.4f})\")\n",
    "print(f\"  Worst Activity:              {activity_scores_svm[-1][0]} (F1: {activity_scores_svm[-1][1]:.4f})\")\n",
    "print(f\"  Activities Won (vs RF):      1/18 (Walk-backward)\")\n",
    "print(f\"  Weighted F1-Score:           {svm_report_dict['weighted avg']['f1-score']:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"Key Findings:\")\n",
    "print(\"  1. Random Forest significantly outperforms SVM (93.78% vs 71.78%)\")\n",
    "print(\"  2. Ensemble methods handle complex activity patterns better than linear classifiers\")\n",
    "print(\"  3. Standard deviation features are most important (44.95% total importance)\")\n",
    "print(\"  4. Gyroscope and Accelerometer contribute equally (~50% each)\")\n",
    "print(\"  5. SVM failed completely on 'Run' activity (0% F1-score)\")\n",
    "print(\"  6. Both models struggle with similar static activities (Stand, Sit, Lay)\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ Project analysis complete!\")\n",
    "print(\"✓ Ready to save models and conclude!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c62538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SECTION 12: SAVE MODELS\n",
    "# ============================================================\n",
    "\n",
    "import joblib\n",
    "\n",
    "print(\"Saving trained models...\")\n",
    "\n",
    "# Save Random Forest\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "print(\"✓ Random Forest saved as: random_forest_model.pkl\")\n",
    "\n",
    "# Save SVM\n",
    "joblib.dump(svm_model, 'svm_model.pkl')\n",
    "print(\"✓ SVM saved as: svm_model.pkl\")\n",
    "\n",
    "# Save Scaler (important!)\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "print(\"✓ Scaler saved as: scaler.pkl\")\n",
    "\n",
    "print(\"\\n✓ All models saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
